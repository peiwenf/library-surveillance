{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "from scipy import stats\n",
    "# import the dataframe that you want to generate reports for\n",
    "df = pd.read_csv(str(os. getcwd())+\"/public_lib_tracker.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the normality \n",
    "column_values = df['number_of_total_trackers_homepage']\n",
    "column_values = column_values.dropna()\n",
    "# Perform Shapiro-Wilk test\n",
    "stats.shapiro(column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is a difference among the categorical variables\n",
    "df = pd.read_csv(str(os. getcwd())+\"/public_lib_tracker.csv\")\n",
    "df.dropna(subset=['number_of_total_trackers_catalog', 'Current Automation System Name'], inplace=True)\n",
    "group_freq = df['Current Automation System Name'].value_counts()\n",
    "sorted_freq = group_freq.sort_values(ascending=False)\n",
    "groups = sorted_freq.head(10).index.tolist()\n",
    "results = stats.kruskal(*[df[df['Current Automation System Name'] == group]['number_of_total_trackers_catalog'] for group in groups])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform dunn's test to compare between each groups \n",
    "filtered_df = df[df['Current Automation System Name'].isin(groups)]\n",
    "dunn_results = posthoc_dunn(filtered_df, \n",
    "                            val_col = 'number_of_total_trackers_catalog',\n",
    "                              group_col = 'Current Automation System Name',\n",
    "                                p_adjust = 'holm')\n",
    "dunn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ranking of the tracker rate\n",
    "group_sums = filtered_df.groupby('Current Automation System Name')['number_of_total_trackers_catalog'].sum()\n",
    "\n",
    "# Get the value counts of each group\n",
    "group_counts = filtered_df['Current Automation System Name'].value_counts()\n",
    "\n",
    "# Divide the value counts by the corresponding group sum\n",
    "group_divided_counts = group_sums / group_counts\n",
    "\n",
    "# Sort the divided counts in descending order\n",
    "sorted_divided_counts = group_divided_counts.sort_values(ascending=False)\n",
    "\n",
    "# Print the sorted divided counts\n",
    "print(sorted_divided_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency of the cookies' purpose\n",
    "def parse_array_string(s):\n",
    "    try:\n",
    "        return eval(s) if isinstance(s, str) else None\n",
    "    except (SyntaxError, NameError):\n",
    "        return None\n",
    "\n",
    "# Convert the column with array strings to actual arrays\n",
    "df.iloc[:, 3:] = df.iloc[:, 3:].applymap(parse_array_string)\n",
    "\n",
    "new_df = df.iloc[:, :3].copy()\n",
    "\n",
    "# Apply a function to compute the length of arrays (if they exist) in each column\n",
    "def compute_array_length(arr):\n",
    "    if isinstance(arr, list):\n",
    "        return len(arr)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to the remaining columns and assign the results to new columns\n",
    "new_df = new_df.join(df.iloc[:, 3:].applymap(compute_array_length))\n",
    "\n",
    "filtered_columns = new_df.filter(like='_homepage')\n",
    "\n",
    "# Calculate the sum of each filtered column\n",
    "column_sums = filtered_columns.sum()\n",
    "\n",
    "# Calculate additional statistics for each filtered column\n",
    "column_count = (filtered_columns > 0).sum()\n",
    "column_median = filtered_columns.mask(filtered_columns == 0).median()\n",
    "column_mean = filtered_columns.mask(filtered_columns == 0).mean()\n",
    "column_std = filtered_columns.mask(filtered_columns == 0).std()\n",
    "\n",
    "column_q1 = filtered_columns.mask(filtered_columns == 0).quantile(0.25)\n",
    "column_q3 = filtered_columns.mask(filtered_columns == 0).quantile(0.75)\n",
    "\n",
    "# Create a new DataFrame with the column names and statistics\n",
    "sum_table = pd.DataFrame({\n",
    "    'Column': column_sums.index,\n",
    "    'Sum': column_sums.values,\n",
    "    'Count': column_count.values,\n",
    "    'Median': column_median.values,\n",
    "    'Mean': column_mean.values,\n",
    "    'Std': column_std.values,\n",
    "    'Q1': column_q1.values,\n",
    "    'Q3': column_q3.values\n",
    "})\n",
    "\n",
    "# Display the sum table\n",
    "print(sum_table)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
